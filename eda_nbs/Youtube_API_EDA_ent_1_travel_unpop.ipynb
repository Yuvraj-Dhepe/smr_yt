{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ded80c01-b0b2-42ec-869a-b1037e531964",
   "metadata": {
    "id": "ded80c01-b0b2-42ec-869a-b1037e531964",
    "tags": []
   },
   "source": [
    "# Exploratory Data Anlysis Using Youtube Data Videos from Most Popular Indian Spirituality Channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f640d5-994f-4c29-baf9-1041f04d63ff",
   "metadata": {
    "id": "30f640d5-994f-4c29-baf9-1041f04d63ff",
    "tags": []
   },
   "source": [
    "## 1. Aims, Objectives, Steps & Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224f687a-18b9-4a01-a689-0b90171e5677",
   "metadata": {
    "id": "224f687a-18b9-4a01-a689-0b90171e5677"
   },
   "source": [
    "### 1.1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c983b474-804c-4caa-a144-0c92568f57b6",
   "metadata": {
    "id": "c983b474-804c-4caa-a144-0c92568f57b6"
   },
   "source": [
    "With millions of users and billions of views, YouTube has become a major platform for spirituality content creators to share their knowledge and insights with a global audience. However, understanding what makes a video successful on YouTube can be a challenge, as the platform's algorithm is complex and constantly evolving. Aspiring spirituality content creators can benefit from analyzing successful channels in their niche and identifying trends in their topics and presentation styles. In this project, we will explore the statistics\n",
    "of 9 popular spirituality channels on YouTube to gain insights on their audience, content, and engagement metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668f9a36-b094-494b-9f33-6338acad2d49",
   "metadata": {
    "id": "668f9a36-b094-494b-9f33-6338acad2d49"
   },
   "source": [
    "### 1.2 Aims and Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630840e1-0733-4b05-b6a8-9a3394e2c735",
   "metadata": {
    "id": "630840e1-0733-4b05-b6a8-9a3394e2c735",
    "tags": []
   },
   "source": [
    "Within this project, I would like to explore the following:\n",
    "\n",
    "- Getting to know Youtube API and how to obtain video data.\n",
    "- Analyzing video data and verify different common \"myths\" about what makes a video do well on Youtube, for example:\n",
    "    - Does the number of likes and comments matter for a video to get more views?\n",
    "    - Does the video duration matter for views and interaction (likes/ comments)?\n",
    "    - Does title length matter for views?\n",
    "    - How many tags do good performing videos have? What are the common tags among these videos?\n",
    "    - Across all the creators I take into consideration, how often do they upload new videos? On which days in the week?\n",
    "\n",
    "- Explore the trending topics using NLP techniques\n",
    "    - Which popular topics are being covered in the videos (e.g. using wordcloud for video titles)?\n",
    "- Which questions are being asked in the comment sections in the videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f59b2a-8dfc-487d-8b92-91d42abd40a7",
   "metadata": {
    "id": "f8f59b2a-8dfc-487d-8b92-91d42abd40a7",
    "tags": []
   },
   "source": [
    "### 1.3 Steps of the project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d70b801-a7fd-4804-8c5b-0c8099a3a985",
   "metadata": {
    "id": "9d70b801-a7fd-4804-8c5b-0c8099a3a985"
   },
   "source": [
    "- Obtain video meta data via the API app, from top 10 youtube niche channels.\n",
    "- Preprocess data and engineer aditional features for analysis\n",
    "- Exploratory data analysis\n",
    "- Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c441642d-f556-47fb-84b9-7cbef6e788c2",
   "metadata": {
    "id": "c441642d-f556-47fb-84b9-7cbef6e788c2",
    "tags": []
   },
   "source": [
    "### 1.4 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2f4349-838d-4a15-8ac8-c237f0c7b960",
   "metadata": {
    "id": "0b2f4349-838d-4a15-8ac8-c237f0c7b960"
   },
   "source": [
    "- Created my own dataset usign the Google API version 3.0\n",
    "- The channels are included as per my liking and self-thoughts about spirituality.\n",
    "- Also I have chosen channels based on their subscriber counts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ba357f-821d-4086-8dc1-2240f98973f5",
   "metadata": {
    "id": "d1ba357f-821d-4086-8dc1-2240f98973f5",
    "tags": []
   },
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baf7acdd-9473-4812-b9fb-61b412e49b43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "executionInfo": {
     "elapsed": 478,
     "status": "error",
     "timestamp": 1701710588271,
     "user": {
      "displayName": "Urvi Virkar",
      "userId": "04095221383775186642"
     },
     "user_tz": -60
    },
    "id": "baf7acdd-9473-4812-b9fb-61b412e49b43",
    "outputId": "79363a10-65dc-493c-a347-af0ee150b324",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/yuvi_dh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/yuvi_dh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from dateutil import parser\n",
    "import isodate\n",
    "import datetime\n",
    "\n",
    "# Data visualization libraries\n",
    "import matplotlib\n",
    "# matplotlib.use('TkAgg') #default backend 'module://matplotlib_inline.backend_inline'\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns\n",
    "sns.set(style = 'darkgrid', color_codes=True)\n",
    "#plt.rcParams['font.family'] = 'Lohit-Devanagari'\n",
    "#plt.rcParams[\"font.path\"] = \"/usr/share/fonts/truetype/lohit-devanagari/Lohit-Devanagari.ttf\"\n",
    "english_font = fm.FontProperties(family = 'Arial', size = 14)\n",
    "#mangal_font = fm.FontProperties(fname = \"~/downloads/fonts/mangal.ttf\",size = 14)\n",
    "#%matplotlib inline\n",
    "#NLP Libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Google API\n",
    "from googleapiclient.discovery import build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5df16d-1353-4ebf-9f83-cbdac5039d62",
   "metadata": {
    "id": "fd5df16d-1353-4ebf-9f83-cbdac5039d62",
    "tags": []
   },
   "source": [
    "## Data Creation with Youtube API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e13910d-e956-4d6c-8e8a-839646deedc7",
   "metadata": {
    "id": "5e13910d-e956-4d6c-8e8a-839646deedc7"
   },
   "source": [
    "- Created a project on Google Developer Console\n",
    "- Requested an Authorization Credential API Key\n",
    "- Enabled Youtube API for the project work to send API requests to Youtube API services.\n",
    "- Got the channel ID's from my favorite channels which I would like to get stats on.\n",
    "- Finally created the functions for getting the channel stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0a38772-8659-48de-978f-e772183bf0a6",
   "metadata": {
    "id": "d0a38772-8659-48de-978f-e772183bf0a6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "api_key_1 = os.environ.get('yt_1')\n",
    "api_key_2 = os.environ.get('yt_2')\n",
    "api_key_3 = os.environ.get('yt_3')\n",
    "api_key_4 =os.environ.get('db_api_1')\n",
    "api_key_5 =os.environ.get('db_api_1')\n",
    "api_key_6 =os.environ.get('db_api_1')\n",
    "api_key_7 =os.environ.get('db_api_1')\n",
    "api_key_8 =os.environ.get('db_api_1')\n",
    "api_key = api_key_1\n",
    "\n",
    "#Auto Channel ID's\n",
    "channel_ids = \"\"\"UCibAe38vV5bkUnReP4riHTw\n",
    "UCEeHmfGLcSga8gRlHCMt6zg\n",
    "UCymrhn6xwPcP_9vteK-zBeQ\n",
    "UCa7bR7ifIPG_Py-SlFo5wOw\n",
    "UCfA8Uw1BTODJDxSrJcIwNCQ\n",
    "UCwqDAwhG1JCxTNr6HnB7gnQ\n",
    "UCI9mLksLjGiqX8HJ2ojB0uA\n",
    "UCKH0DuBnfp2Ox7QF8ICsZHQ\n",
    "UCqSwaBPn_p0oQhRFU-0SxmA\n",
    "UCBElRVEL-H0eDYdL2mb1Sng\n",
    "\"\"\".split('\\n')\n",
    "youtube = build('youtube', 'v3',developerKey=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb49cbed-14a4-471e-932d-c10ca7151c66",
   "metadata": {
    "id": "eb49cbed-14a4-471e-932d-c10ca7151c66",
    "tags": []
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90603483-c873-46d3-aa19-a6e583e61155",
   "metadata": {
    "id": "90603483-c873-46d3-aa19-a6e583e61155",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_channel_stats(channel_ids,yt=youtube):\n",
    "    '''\n",
    "    Get Channel statistics: title subscriber count, view count, video count, upload playlist\n",
    "\n",
    "    Params:\n",
    "    youtube: the build object from googleapiclient.discovery\n",
    "    channel_ids: list of channel IDs\n",
    "\n",
    "    Returns:\n",
    "    Dataframe containing the channel statistics for all channels in the provided list\n",
    "\n",
    "    '''\n",
    "    all_data = []\n",
    "    request = youtube.channels().list(\n",
    "        part = 'snippet,contentDetails,statistics,brandingSettings',\n",
    "        id=','.join(channel_ids))\n",
    "    response = request.execute()\n",
    "\n",
    "    for i in range(len(response['items'])):\n",
    "        data = dict(channelName = response['items'][i]['snippet']['title'],\n",
    "                    # countryName = response['items'][i]['snippet'][\"country\"],\n",
    "                    subscribers = response['items'][i]['statistics']['subscriberCount'],\n",
    "                    views = response['items'][i]['statistics']['viewCount'],\n",
    "                    totalVideos = response['items'][i]['statistics']['videoCount'],\n",
    "                    playlistId = response['items'][i]['contentDetails']['relatedPlaylists']['uploads'],\n",
    "                   publishedAt = isodate.parse_datetime(response['items'][i]['snippet']['publishedAt']))\n",
    "\n",
    "        all_data.append(data)\n",
    "    return pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95f10e55-85c5-4cd1-a8b3-f0ac931bb3ba",
   "metadata": {
    "id": "95f10e55-85c5-4cd1-a8b3-f0ac931bb3ba",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_video_ids(playlist_id, max_results=1000,yt = youtube):\n",
    "    \"\"\"\n",
    "    Get list of video IDs of all videos in the given playlist, up to a maximum of 1500 videos\n",
    "    Params:\n",
    "\n",
    "    youtube: the build object from googleapiclient.discovery\n",
    "    playlist_id: playlist ID of the channel\n",
    "    max_results: maximum number of videos to retrieve (default: 1500)\n",
    "\n",
    "    Returns:\n",
    "    List of video IDs of all videos in the playlist, up to the maximum number of videos specified\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    request = youtube.playlistItems().list(\n",
    "                part='contentDetails',\n",
    "                playlistId = playlist_id,\n",
    "                maxResults = min(max_results, 50))\n",
    "    response = request.execute()\n",
    "\n",
    "    video_ids = []\n",
    "    num_videos = 0\n",
    "\n",
    "    for i in range(len(response['items'])):\n",
    "        video_ids.append(response['items'][i]['contentDetails']['videoId'])\n",
    "        num_videos += 1\n",
    "        if num_videos >= max_results:\n",
    "            break\n",
    "\n",
    "    next_page_token = response.get('nextPageToken')\n",
    "    more_pages = True\n",
    "\n",
    "    while more_pages and num_videos < max_results:\n",
    "        if next_page_token is None:\n",
    "            more_pages = False\n",
    "        else:\n",
    "            request = youtube.playlistItems().list(\n",
    "                        part='contentDetails',\n",
    "                        playlistId = playlist_id,\n",
    "                        maxResults = min(max_results - num_videos, 50),\n",
    "                        pageToken = next_page_token)\n",
    "            response = request.execute()\n",
    "\n",
    "            for i in range(len(response['items'])):\n",
    "                video_ids.append(response['items'][i]['contentDetails']['videoId'])\n",
    "                num_videos += 1\n",
    "                if num_videos >= max_results:\n",
    "                    break\n",
    "\n",
    "            next_page_token = response.get('nextPageToken')\n",
    "\n",
    "    return video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d927228-54ff-4044-9454-3b23680fcba1",
   "metadata": {
    "id": "6d927228-54ff-4044-9454-3b23680fcba1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_video_details(video_ids,yt = youtube):\n",
    "    \"\"\"\n",
    "    Get video statistics of all videos with given IDs\n",
    "    Params:\n",
    "\n",
    "    youtube: the build object from googleapiclient.discovery\n",
    "    video_ids: list of video IDs\n",
    "\n",
    "    Returns:\n",
    "    Dataframe with statistics of videos, i.e.:\n",
    "        'channelTitle', 'title', 'description', 'tags', 'publishedAt'\n",
    "        'viewCount', 'likeCount', 'commentCount'\n",
    "        'duration', 'definition', 'caption'\n",
    "    \"\"\"\n",
    "\n",
    "    all_video_info = []\n",
    "\n",
    "    for i in range(0, len(video_ids), 50):\n",
    "        request = youtube.videos().list(\n",
    "            part=\"snippet,contentDetails,statistics\",\n",
    "            id=','.join(video_ids[i:i+50])\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        for video in response['items']:\n",
    "            stats_to_keep = {'snippet': ['channelTitle', 'title', 'description', 'tags', 'publishedAt'],\n",
    "                             'statistics': ['viewCount', 'likeCount', 'commentCount'],\n",
    "                             'contentDetails': ['duration', 'definition', 'caption']\n",
    "                            }\n",
    "            video_info = {}\n",
    "            video_info['video_id'] = video['id']\n",
    "\n",
    "            for k in stats_to_keep.keys():\n",
    "                for v in stats_to_keep[k]:\n",
    "                    try:\n",
    "                        video_info[v] = video[k][v]\n",
    "                    except:\n",
    "                        video_info[v] = None\n",
    "\n",
    "            all_video_info.append(video_info)\n",
    "\n",
    "    return pd.DataFrame(all_video_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd14f812-0327-4f2a-a997-7104fba4ef36",
   "metadata": {
    "id": "dd14f812-0327-4f2a-a997-7104fba4ef36",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_comments_in_videos(video_ids, yt = youtube):\n",
    "    \"\"\"\n",
    "    Get top level comments as text from all videos with given IDs (only the first 10 comments due to quote limit of Youtube API)\n",
    "    Params:\n",
    "\n",
    "    youtube: the build object from googleapiclient.discovery\n",
    "    video_ids: list of video IDs\n",
    "\n",
    "    Returns:\n",
    "    Dataframe with video IDs and associated top level comment in text.\n",
    "\n",
    "    \"\"\"\n",
    "    all_comments = []\n",
    "\n",
    "    for video_id in video_ids:\n",
    "        try:\n",
    "            request = youtube.commentThreads().list(\n",
    "                part=\"snippet,replies\",\n",
    "                videoId=video_id\n",
    "            )\n",
    "            response = request.execute()\n",
    "\n",
    "            comments_in_video = [comment['snippet']['topLevelComment']['snippet']['textOriginal'] for comment in response['items'][0:10]]\n",
    "            comments_in_video_info = {'video_id': video_id, 'comments': comments_in_video}\n",
    "\n",
    "            all_comments.append(comments_in_video_info)\n",
    "\n",
    "        except:\n",
    "            # When error occurs - most likely because comments are disabled on a video\n",
    "            print('Could not get comments for video ' + video_id)\n",
    "\n",
    "    return pd.DataFrame(all_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8fbd96-7540-48d8-959f-73da435c1233",
   "metadata": {
    "id": "5b8fbd96-7540-48d8-959f-73da435c1233",
    "tags": []
   },
   "source": [
    "### Get Channel statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e89242e-dcc6-4f36-bd15-15fcf0a6601c",
   "metadata": {
    "id": "8e89242e-dcc6-4f36-bd15-15fcf0a6601c"
   },
   "source": [
    "Using the get_channel_stats function defined below, now we are going to obtain the channel statistics for the above channels in scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c49ec5-a98d-442c-bc2b-02ffb6471378",
   "metadata": {
    "id": "54c49ec5-a98d-442c-bc2b-02ffb6471378",
    "tags": []
   },
   "outputs": [],
   "source": [
    "channel_data = get_channel_stats(channel_ids)\n",
    "channel_data.to_csv(\"./travel/bottom_travel_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d50717-e752-492c-a4d1-fa0971de0fd3",
   "metadata": {
    "id": "29d50717-e752-492c-a4d1-fa0971de0fd3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "channel_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9f8c0f-e9f8-4649-87ed-c47468791820",
   "metadata": {
    "id": "ba9f8c0f-e9f8-4649-87ed-c47468791820",
    "outputId": "6c4f17df-52c1-4e2c-e5ab-924405862a57",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creation of copy so that I save a dummy df and also a csv, to not keep reusing youtube credits i.e. 10k per day.\n",
    "l_channel_data = pd.read_csv(\"./travel/bottom_travel_info.csv\",index_col=0)\n",
    "l_channel_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e1bc32-9170-428c-a648-ae30157028d8",
   "metadata": {
    "id": "d5e1bc32-9170-428c-a648-ae30157028d8",
    "outputId": "ffba7c4e-56b8-42b7-ee8f-5cff0fb249c1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copy used for further manipulation and original of l_channel_data can be used to load this chdd any time.\n",
    "chdd = l_channel_data.copy()\n",
    "chdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41101562-323f-4eca-b53b-02ce0a9c9bbc",
   "metadata": {
    "id": "41101562-323f-4eca-b53b-02ce0a9c9bbc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting Numeric n Categorical columns\n",
    "numeric_cols = ['subscribers','views','totalVideos']\n",
    "chdd[numeric_cols] = chdd[numeric_cols].apply(pd.to_numeric,errors = 'coerce')\n",
    "\n",
    "# Convert publishedAt column to datetime\n",
    "chdd['publishedAt'] =(pd.to_datetime(chdd['publishedAt']))\n",
    "\n",
    "# Extract year, month, and time into separate columns\n",
    "chdd['publishingYear'] = chdd['publishedAt'].dt.year\n",
    "chdd['publishingMonth'] = chdd['publishedAt'].dt.month\n",
    "chdd['publishingTime'] = chdd['publishedAt'].dt.time\n",
    "\n",
    "# Get month name\n",
    "chdd['publishingMonthName'] = chdd['publishedAt'].dt.strftime(\"%B\")\n",
    "\n",
    "# Dropping the published At column\n",
    "chdd.drop(['publishedAt'],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0b99b2-12af-4830-b6ec-f8d4eda40778",
   "metadata": {
    "id": "6f0b99b2-12af-4830-b6ec-f8d4eda40778",
    "outputId": "e41400c2-1adc-42d8-f77c-5d8699500e28",
    "tags": []
   },
   "outputs": [],
   "source": [
    "chdd.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7af624-53b4-454e-a8e0-475b97009e66",
   "metadata": {
    "id": "4a7af624-53b4-454e-a8e0-475b97009e66",
    "tags": []
   },
   "source": [
    "### Popularity measure via the number of subscribers per channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5728f59-96f0-4f9c-95d8-b830639e2e50",
   "metadata": {
    "id": "e5728f59-96f0-4f9c-95d8-b830639e2e50",
    "outputId": "a790beaa-c421-4f79-9b22-26b42e92c971",
    "tags": []
   },
   "outputs": [],
   "source": [
    "matplotlib.get_backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f924f06c-0297-4f5f-a7e8-106e9186db00",
   "metadata": {
    "id": "f924f06c-0297-4f5f-a7e8-106e9186db00",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#matplotlib.use??\n",
    "#sns.barplot??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a753989-2f8f-42ab-9353-eafe87ccc46d",
   "metadata": {
    "id": "3a753989-2f8f-42ab-9353-eafe87ccc46d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fixing colors for each channel\n",
    "palette = sns.color_palette('pastel6', n_colors=14)\n",
    "channel_colors = {}\n",
    "chdd.sort_values('subscribers',ascending=False,inplace=True)\n",
    "for i, channel in enumerate(chdd['channelName']):\n",
    "    channel_colors[channel] = palette[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d802597c-84e1-445d-b570-36ec12b1b566",
   "metadata": {
    "id": "d802597c-84e1-445d-b570-36ec12b1b566",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#matplotlib.use??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2f3f2e-fe26-4a40-915f-a5a8866c2817",
   "metadata": {
    "id": "4d2f3f2e-fe26-4a40-915f-a5a8866c2817",
    "outputId": "ac254268-2156-4966-8e22-722ba0856168",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#matplotlib.use('module://matplotlib_inline.backend_inline')\n",
    "sns.set(rc={'figure.figsize':(10,8)})\n",
    "ax = sns.barplot(x='channelName', y='subscribers', data=chdd.sort_values('subscribers', ascending=False), palette=channel_colors)\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000) + 'K'))\n",
    "plot = ax.set_xticklabels(ax.get_xticklabels(),rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449fb25b-559b-4800-9a7d-ed8a3d92b126",
   "metadata": {
    "id": "449fb25b-559b-4800-9a7d-ed8a3d92b126",
    "tags": []
   },
   "source": [
    "### Popularity measure via the number of views per channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9f9fc5-89f9-4dc0-87ae-5e0254a71fbf",
   "metadata": {
    "id": "2a9f9fc5-89f9-4dc0-87ae-5e0254a71fbf",
    "outputId": "ca222788-df27-4dc7-9d35-4dbb846a978f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax = sns.barplot(x='channelName', y='views', data=chdd.sort_values('views', ascending=False),palette=channel_colors)\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000) + 'K'))\n",
    "plot = ax.set_xticklabels(ax.get_xticklabels(),rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4839a888-9b63-42f9-ae5c-5401cb0880c9",
   "metadata": {
    "id": "4839a888-9b63-42f9-ae5c-5401cb0880c9"
   },
   "source": [
    "#### Observation from above stats:\n",
    "- Interestingly, some channels have more subscribers but less views and vice versa. For example, GGD channel has significantly more subscribers than Mind Valley channel, but less views in total.\n",
    "- Psych2Go and The School of Life hold onto their ranks in both views and subscriber count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653a8294-e14c-424f-9a1d-208d6cef27c9",
   "metadata": {
    "id": "653a8294-e14c-424f-9a1d-208d6cef27c9",
    "tags": []
   },
   "source": [
    "### Get video statistics for all the channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40b72dd-a6ad-4be6-a55c-e81a8a3f0cb2",
   "metadata": {
    "id": "e40b72dd-a6ad-4be6-a55c-e81a8a3f0cb2"
   },
   "source": [
    "In the next step, we will obtain the video statistics for all the channels. In total, we obtained 3,722 videos as seen in below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959970fb-d999-4257-8182-2947012ba66a",
   "metadata": {
    "id": "959970fb-d999-4257-8182-2947012ba66a",
    "outputId": "5d24e2ec-46c0-49d2-92e2-c5b7639505d5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a dataframe with video statistics and comments from all channels\n",
    "video_df = pd.DataFrame()\n",
    "comments_df = pd.DataFrame()\n",
    "\n",
    "for c in channel_data['channelName'].unique():\n",
    "    print(\"Getting video information from channel: \" + c)\n",
    "    playlist_id = channel_data.loc[channel_data['channelName']== c, 'playlistId'].iloc[0]\n",
    "    video_ids = get_video_ids(playlist_id,max_results=1000,yt = youtube)\n",
    "\n",
    "    # get video data\n",
    "    video_data = get_video_details(video_ids,yt = youtube)\n",
    "    # get comment data\n",
    "    comments_data = get_comments_in_videos(video_ids,yt = youtube)\n",
    "\n",
    "    # append video data together and comment data toghether\n",
    "    video_df = video_df.append(video_data, ignore_index=True)\n",
    "    comments_df = comments_df.append(comments_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e4ff68-5c39-4d8e-9075-b0af0082150f",
   "metadata": {
    "id": "f9e4ff68-5c39-4d8e-9075-b0af0082150f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_df.to_csv(\"./travel/bottom_travel_vid.csv\")\n",
    "comments_df.to_csv(\"./travel/bottom_travel_comments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac6b7a3-5a6f-4092-9d0d-6af546bb49a0",
   "metadata": {
    "id": "7ac6b7a3-5a6f-4092-9d0d-6af546bb49a0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "l_video_df = pd.read_csv(\"./travel/bottom_travel_vid.csv\",index_col=0)\n",
    "l_comments_df = pd.read_csv(\"./travel/bottom_travel_comments.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb7aeaa-e5bb-4560-bc4b-62683dfa774d",
   "metadata": {
    "id": "feb7aeaa-e5bb-4560-bc4b-62683dfa774d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "viddf = l_video_df.copy()\n",
    "comdf = l_comments_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec118468-d6f2-4f71-8b4a-e491d82ecb00",
   "metadata": {
    "id": "ec118468-d6f2-4f71-8b4a-e491d82ecb00",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create publish day (in the week) column\n",
    "viddf['publishedAt'] =  viddf['publishedAt'].apply(lambda x: parser.parse(x))\n",
    "viddf['pushblishDayName'] = viddf['publishedAt'].apply(lambda x: x.strftime(\"%A\"))\n",
    "\n",
    "# Convert publishedAt column to datetime\n",
    "viddf['publishedAt'] =(pd.to_datetime(viddf['publishedAt']))\n",
    "\n",
    "\n",
    "# Extract year, month, and time into separate columns\n",
    "viddf['publishingYear'] = viddf['publishedAt'].dt.year\n",
    "viddf['publishingMonth'] = viddf['publishedAt'].dt.month\n",
    "viddf['publishingTime'] = viddf['publishedAt'].dt.time\n",
    "\n",
    "# Get month name\n",
    "viddf['publishingMonthName'] = viddf['publishedAt'].dt.strftime(\"%B\")\n",
    "\n",
    "# Dropping the published At column\n",
    "viddf.drop(['publishedAt'],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e445fe-0f35-4102-a68a-c5905963780d",
   "metadata": {
    "id": "f0e445fe-0f35-4102-a68a-c5905963780d",
    "outputId": "9f146fe6-7d96-49d6-be13-72c8e0a9fb7a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "viddf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c46fb7-53e3-41fc-b486-023316a02606",
   "metadata": {
    "id": "98c46fb7-53e3-41fc-b486-023316a02606",
    "tags": []
   },
   "source": [
    "Let's take a look at the comment_df as well. We only get 9305 comments in total due to the fact that we limited to 10 first comments on the video to avoid exceeding the Youtube API quota limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e057df0-8fd2-4b1c-bf0e-acd5d9ce20e5",
   "metadata": {
    "id": "8e057df0-8fd2-4b1c-bf0e-acd5d9ce20e5",
    "outputId": "e3fdcb44-f39a-41af-9d02-3cdb122a1e25",
    "tags": []
   },
   "outputs": [],
   "source": [
    "comdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfb07ac-ffd3-4427-932c-124f7e2abe14",
   "metadata": {
    "id": "ddfb07ac-ffd3-4427-932c-124f7e2abe14"
   },
   "source": [
    "## Preprocessing & Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b49fad1-9739-4077-8ec4-ebc73bc390ad",
   "metadata": {
    "id": "5b49fad1-9739-4077-8ec4-ebc73bc390ad"
   },
   "source": [
    "To be able to make use of the data for analysis, we need to perform a few pre-processing steps. Firstly, I would like reformat some columns, especially the date and time columns such as \"pushlishedAt\" and \"duration\". In addition, I also think it is necessary to enrich the data with some new features that might be useful for understanding the videos' characteristics. Also I removed the favorite count column as it's completely blank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efce59d-799a-4bc8-a67d-40cc022894f5",
   "metadata": {
    "id": "7efce59d-799a-4bc8-a67d-40cc022894f5",
    "tags": []
   },
   "source": [
    "### Check for empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a817dc3c-8800-40de-8a38-fab797f62bb7",
   "metadata": {
    "id": "a817dc3c-8800-40de-8a38-fab797f62bb7",
    "outputId": "48c64b4d-aa2a-4ad5-a0db-f8d3be3eef6c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "viddf.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85478c8a-43ff-4611-bbe9-db829ac48f28",
   "metadata": {
    "id": "85478c8a-43ff-4611-bbe9-db829ac48f28",
    "outputId": "6fe02793-61c4-4ee4-fcbf-b70be38d5710",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.heatmap(viddf.isnull(),yticklabels = False, cbar = False, cmap = 'viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe9e56a-ecb7-437b-90ff-5edb2c4af017",
   "metadata": {
    "id": "dbe9e56a-ecb7-437b-90ff-5edb2c4af017"
   },
   "source": [
    "### Formatting Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfa7809-6f80-46df-9fb0-b74d92e90b8a",
   "metadata": {
    "id": "0dfa7809-6f80-46df-9fb0-b74d92e90b8a",
    "outputId": "77fc1569-84ab-4821-bd8f-b29ebcf760b2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "viddf.publishingYear.sort_values().value_counts()\n",
    "# Videos are from 2011 to 2023\n",
    "#- During the covid time the channels became more active it seems over all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea3e861-0561-4c2d-aa4b-24a1255dfcfc",
   "metadata": {
    "id": "2ea3e861-0561-4c2d-aa4b-24a1255dfcfc"
   },
   "source": [
    "### Correcting Data types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5238f0a9-0086-47cd-8af2-238bfa3f769e",
   "metadata": {
    "id": "5238f0a9-0086-47cd-8af2-238bfa3f769e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = ['viewCount', 'likeCount', 'commentCount']\n",
    "viddf[cols] = viddf[cols].apply(pd.to_numeric, errors='coerce', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed1769b-7df5-42ef-8e9c-89b9014a309c",
   "metadata": {
    "id": "6ed1769b-7df5-42ef-8e9c-89b9014a309c",
    "tags": []
   },
   "source": [
    "#### Enriching data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d90678-9924-4fa8-806b-67f1235ad5cd",
   "metadata": {
    "id": "a4d90678-9924-4fa8-806b-67f1235ad5cd",
    "tags": []
   },
   "source": [
    "I want to enrich the data for further analyses, for example:\n",
    "- convert video duration to seconds instead of the current default string format\n",
    "- calculate number of tags for each video\n",
    "- calculate comments and likes per 1000 view ratio\n",
    "- calculate title character length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea75f4a-3618-4ce6-ad49-9da1658c7c43",
   "metadata": {
    "id": "0ea75f4a-3618-4ce6-ad49-9da1658c7c43",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert duration to seconds\n",
    "viddf['durationSecs'] = viddf['duration'].apply(lambda x: isodate.parse_duration(x))\n",
    "viddf['durationSecs'] = viddf['durationSecs'].astype('timedelta64[s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9b22d9-ffe5-446e-94a4-4e6ee7c383de",
   "metadata": {
    "id": "ee9b22d9-ffe5-446e-94a4-4e6ee7c383de",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add number of tags\n",
    "viddf['tagsstr'] = viddf.tags.apply(lambda x: 0 if x is None else str((x))) #tags were not in proper format so converting them to str\n",
    "viddf['tagsCount'] = viddf.tagsstr.apply(lambda x: 0 if (x == 0 or x =='nan') else len(eval(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cd72ea-2ee6-415b-973d-458c39de8469",
   "metadata": {
    "id": "68cd72ea-2ee6-415b-973d-458c39de8469",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Comments and likes per 1000 view ratio\n",
    "viddf['likeRatio'] = viddf['likeCount']/ viddf['viewCount'] * 1000\n",
    "viddf['commentRatio'] = viddf['commentCount']/ viddf['viewCount'] * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094ecd04-bced-42cf-ad66-ab0d2af19924",
   "metadata": {
    "id": "094ecd04-bced-42cf-ad66-ab0d2af19924",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Title character length\n",
    "viddf['titleLength'] = viddf['title'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e82061-8670-4e89-b589-500dae5a5667",
   "metadata": {
    "id": "16e82061-8670-4e89-b589-500dae5a5667",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dropping the favourite Count as all of it is empty\n",
    "# viddf.drop(['favouriteCount'],axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a762288-ba56-44bd-a34b-ba73aa1bf6e0",
   "metadata": {
    "id": "3a762288-ba56-44bd-a34b-ba73aa1bf6e0"
   },
   "source": [
    "Taking a look at the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b878e5-9fc9-4038-a5d1-08e1b8859ff2",
   "metadata": {
    "id": "59b878e5-9fc9-4038-a5d1-08e1b8859ff2"
   },
   "source": [
    "## Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42cd768-72a9-45a6-8d21-38479bff90ba",
   "metadata": {
    "id": "e42cd768-72a9-45a6-8d21-38479bff90ba"
   },
   "source": [
    "### Views distribution per channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09179c65-3538-4d86-a4fa-519d11dfa5a6",
   "metadata": {
    "id": "09179c65-3538-4d86-a4fa-519d11dfa5a6",
    "tags": []
   },
   "source": [
    "With the video statistics for all channel, now we can see how the views are distributed per channel. Some channels might have a lot of views on one of their videos and the rest do not receive many views. Few channels like Gaeia, Vishuddha Das, might have more evenly distribution views per video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac72bc7-268c-450b-8a8b-69fc5d167c70",
   "metadata": {
    "id": "3ac72bc7-268c-450b-8a8b-69fc5d167c70",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# # Create a MinMaxScaler object\n",
    "# scaler = MinMaxScaler()\n",
    "# dfd = viddf.copy()\n",
    "# # Normalize the viewCount and likeCount columns it didn't help much in plotting cause every value was transformed relatively so used the dynamic plotting to view the plots\n",
    "# dfd[['viewCount', 'likeCount']] = scaler.fit_transform(dfd[['viewCount', 'likeCount']])\n",
    "# dfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60788a77-687f-4f19-955d-44efbe16a440",
   "metadata": {
    "id": "60788a77-687f-4f19-955d-44efbe16a440",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# matplotlib.use(\"TkAgg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f824b79e-533e-4b6d-9ba2-733d93c5621c",
   "metadata": {
    "id": "f824b79e-533e-4b6d-9ba2-733d93c5621c",
    "outputId": "ed3d976c-4640-4908-968d-901dc8da2ff8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(10,8),'figure.dpi':100})\n",
    "ax = sns.violinplot(x='channelTitle', y='viewCount', data=viddf.sort_values('viewCount', ascending=False), palette = channel_colors)\n",
    "# ax.set_ylim(ymin= 1e-9,ymax=1e9)\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000) + 'K'))\n",
    "plot = ax.set_xticklabels(ax.get_xticklabels(),rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cb2faf-047a-4be2-8c5f-70b7092783ee",
   "metadata": {
    "id": "21cb2faf-047a-4be2-8c5f-70b7092783ee"
   },
   "source": [
    "### Does the number of likes and comments matter for a video to get more views?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e07395f-8340-47d7-8a9b-55364a017b26",
   "metadata": {
    "id": "3e07395f-8340-47d7-8a9b-55364a017b26"
   },
   "source": [
    "Firstly, I would like to check if comments and likes do correlate with how many views a video would get. In the plots below, it can be observed that the number of views and number of comments/ likes strongly correlated with each other. The number of likes seems to suggest stronger correlation than the number of comments. However, this is expected as the more people watching a video, the more likely this video will get comments and likes. To correct for this factor, we will plot these relationships again using the comments per 1000 view and likes per 1000 view ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b121e5-6c62-47c5-8023-b331fc1aade9",
   "metadata": {
    "id": "72b121e5-6c62-47c5-8023-b331fc1aade9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(matplotlib.rcsetup.all_backends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f5f2c5-5542-4abe-91cf-aaf675a843ab",
   "metadata": {
    "id": "e2f5f2c5-5542-4abe-91cf-aaf675a843ab",
    "outputId": "bfd2958f-8d2c-4bf1-9f6c-ae6f71132416",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(1,2)\n",
    "sns.scatterplot(data = viddf, x = \"commentCount\", y = \"viewCount\", ax=ax[0])\n",
    "sns.scatterplot(data = viddf, x = \"likeCount\", y = \"viewCount\", ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3c13bd-f751-49d3-8f9b-8b9b2786d8a7",
   "metadata": {
    "id": "7a3c13bd-f751-49d3-8f9b-8b9b2786d8a7"
   },
   "source": [
    "Now we will take a look at the correlation if we look at the comment ratio and like ratio instead of the absolute number. It seems that more views is leading to more comments and more likes as well, but after a certain point I think, with views viewers, don't write comments that much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f7db2e-098a-4f35-bc47-0477b0c38a4c",
   "metadata": {
    "id": "96f7db2e-098a-4f35-bc47-0477b0c38a4c",
    "outputId": "6eafdc74-eda1-498c-fa3c-aeeaaa5dca86",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(1,2)\n",
    "sns.scatterplot(data = viddf, x = \"commentRatio\", y = \"viewCount\", ax=ax[0])\n",
    "#ax[0].set_ylim(0,9e6)\n",
    "#ax[1].set_ylim(0,9e6)\n",
    "sns.scatterplot(data = viddf, x = \"likeRatio\", y = \"viewCount\", ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8c69e2-2449-4183-8a61-9ca9420395fc",
   "metadata": {
    "id": "df8c69e2-2449-4183-8a61-9ca9420395fc"
   },
   "source": [
    "### Does the video duration matter for views and interaction (likes/ comments)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db16d5a0-fa66-4c07-994a-8a56d50a5d91",
   "metadata": {
    "id": "db16d5a0-fa66-4c07-994a-8a56d50a5d91"
   },
   "source": [
    "As can be seen in the histogram below, most videos are between 1600 to 1800 seconds, which is about 20 to 30 minutes. Here I have to limit the duration to 10,000 because of some really long videos (potentially streaming videos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d986fa3-6314-44c3-beec-76b965b80ee2",
   "metadata": {
    "id": "6d986fa3-6314-44c3-beec-76b965b80ee2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sns.histplot??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8137f933-5118-42aa-bd3b-be1b978a27db",
   "metadata": {
    "id": "8137f933-5118-42aa-bd3b-be1b978a27db",
    "outputId": "f78c471b-bff8-4c5b-fd4e-6893b3df57e7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.histplot(data=viddf[viddf['durationSecs'] < 10000], x=\"durationSecs\", bins=30, color=\"#9368b7\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4b6dc2-163c-4201-b87a-07ddae96340d",
   "metadata": {
    "id": "dd4b6dc2-163c-4201-b87a-07ddae96340d"
   },
   "source": [
    "Now we plot the duration against comment count and like count. It can be seen that actually shorter videos tend to get more likes and comments than very long videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566fa38c-490f-4534-8e1c-a068ef458d8d",
   "metadata": {
    "id": "566fa38c-490f-4534-8e1c-a068ef458d8d",
    "outputId": "461ede15-47ee-45b1-bf23-fba9d71f591c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(1,2)\n",
    "ax[0].yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000) + 'K'))\n",
    "sns.scatterplot(data = viddf, x = \"durationSecs\", y = \"commentCount\", ax=ax[0])\n",
    "sns.scatterplot(data = viddf, x = \"durationSecs\", y = \"likeCount\", ax=ax[1])\n",
    "#ax[0].set_ylim(0,1e5)\n",
    "ax[0].yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000) + 'K'))\n",
    "#ax[1].set_ylim(0,1e5)\n",
    "ax[1].yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000) + 'K'))\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fb9a81-c2dd-455e-929f-88085a901bb1",
   "metadata": {
    "id": "f7fb9a81-c2dd-455e-929f-88085a901bb1",
    "tags": []
   },
   "source": [
    "### Does title length matter for views?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b077aa-3d50-465e-aa8b-1f91880f1cd2",
   "metadata": {
    "id": "f5b077aa-3d50-465e-aa8b-1f91880f1cd2"
   },
   "source": [
    "There is no clear relationship between title length and views as seen the scatterplot below, but most-viewed videos tend to have average title length of 35-60 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173b58e2-f22f-4f78-aa87-ce1ee66cb8ff",
   "metadata": {
    "id": "173b58e2-f22f-4f78-aa87-ce1ee66cb8ff",
    "outputId": "5a5993a0-aa9f-4680-da24-f20ababb8d57",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(data = viddf, x = \"titleLength\", y = \"viewCount\")\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000) + 'K'))\n",
    "ax.set_ylim(0,1e7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0728c2-6853-41f7-9c90-8ee9d10ebbe5",
   "metadata": {
    "id": "3b0728c2-6853-41f7-9c90-8ee9d10ebbe5"
   },
   "source": [
    "## Wordcloud for words in title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1524fbc6-8cc8-4133-8d82-0b052ba496e6",
   "metadata": {
    "id": "1524fbc6-8cc8-4133-8d82-0b052ba496e6"
   },
   "source": [
    "As I'm interested to see what the creators are making videos about and which terms most frequently appear in their video titles, I will create a wordcloud for the most common words. We first need to remove the stopwords such as \"you\", \"I\", \"the\", etc. which do note contribute a lot to the meaning of the title. It can be seen that the main words posted in title are Life, Attraction, Love, Meditation, People and Thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d06823-223d-454b-ad1d-1fd9e341c4f0",
   "metadata": {
    "id": "d8d06823-223d-454b-ad1d-1fd9e341c4f0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "viddf['title_no_stopwords'] = viddf['title'].apply(lambda x: [item for item in str(x).split() if item not in stop_words])\n",
    "\n",
    "all_words = list([a for b in viddf['title_no_stopwords'].tolist() for a in b])\n",
    "all_words_str = ' '.join(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3468933-6e44-42fe-a7bd-3b0b3f8624e7",
   "metadata": {
    "id": "d3468933-6e44-42fe-a7bd-3b0b3f8624e7",
    "outputId": "e81a7db2-2ed2-4b0c-fb36-9abe2c834590",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_cloud(wordcloud):\n",
    "    plt.figure(figsize=(30, 20))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\");\n",
    "\n",
    "wordcloud = WordCloud(width = 1920, height = 780, random_state=1, background_color='black',\n",
    "                      colormap='viridis', collocations=False).generate(all_words_str)\n",
    "plot_cloud(wordcloud)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5532dde-53ff-4f51-aa51-1f326ad2aaf4",
   "metadata": {
    "id": "c5532dde-53ff-4f51-aa51-1f326ad2aaf4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sorted(wordcloud.words_.items(), key = lambda x: x[1],reverse = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e717125e-7321-4c4e-a704-75d78ed75ecb",
   "metadata": {
    "id": "e717125e-7321-4c4e-a704-75d78ed75ecb"
   },
   "source": [
    "### Number of tags vs views"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da8e269-c8ac-4d13-bf10-dddc6b70c6fd",
   "metadata": {
    "id": "3da8e269-c8ac-4d13-bf10-dddc6b70c6fd"
   },
   "source": [
    "It seems that most videos have between 10 and 45 tags. The relationship between number of tags and view count is not clearly seen, but too few tags or too many tags do seem to correlate with fewer views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0061934e-f9d7-4c77-96d9-5134e1aaf296",
   "metadata": {
    "id": "0061934e-f9d7-4c77-96d9-5134e1aaf296",
    "outputId": "adeb4844-0462-4c26-aec7-3e845b75e114",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot = sns.scatterplot(data = viddf, x = \"tagsCount\", y = \"viewCount\")\n",
    "plot.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000) + 'K'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feaf6b7-2453-48d1-a675-f68aa7b6f17f",
   "metadata": {
    "id": "7feaf6b7-2453-48d1-a675-f68aa7b6f17f"
   },
   "source": [
    "### Which day in the week are most videos uploaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5e177b-a759-4e18-9990-280dbf67a297",
   "metadata": {
    "id": "9b5e177b-a759-4e18-9990-280dbf67a297"
   },
   "source": [
    "It's interesting to see that more videos are uploaded on Mondays, Wednesdays and Fridays. It seems the pattern is alternative in uploading the videos. This might be because of maintaining a consistency on channel, like when the user can more expect the videos, on a consistent basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d721ce-affb-4c03-aa35-3a8019804031",
   "metadata": {
    "id": "21d721ce-affb-4c03-aa35-3a8019804031",
    "outputId": "203d1555-cccd-485b-a097-de404207c7dc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "day_df = pd.DataFrame(viddf['pushblishDayName'].value_counts())\n",
    "weekdays = [ 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "day_df = day_df.reindex(weekdays)\n",
    "ax = day_df.reset_index().plot.bar(x='index', y='pushblishDayName', rot=0)\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.legend(labels = [\"Counts\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e92a1ad-9b10-481c-aa51-d9fb06009a39",
   "metadata": {
    "id": "0e92a1ad-9b10-481c-aa51-d9fb06009a39"
   },
   "source": [
    "## Wordcloud for video comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4152aae-7a65-46b7-820e-db5e13cdf093",
   "metadata": {
    "id": "c4152aae-7a65-46b7-820e-db5e13cdf093",
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "comdf['comments_no_stopwords'] = comdf['comments'].apply(lambda x: [item for item in str(x).split() if item not in stop_words])\n",
    "\n",
    "all_words = list([a for b in comdf['comments_no_stopwords'].tolist() for a in b])\n",
    "all_words_str = ' '.join(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad16a34c-142d-4e4c-a058-a71f959c557a",
   "metadata": {
    "id": "ad16a34c-142d-4e4c-a058-a71f959c557a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width = 1980, height = 720, random_state=1, background_color='black',\n",
    "                      colormap='viridis', collocations=False).generate(all_words_str)\n",
    "plot_cloud(wordcloud)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
